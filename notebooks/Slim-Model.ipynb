{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import argparse\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"/data/slim/models/research/slim/\")\n",
    "from nets import nets_factory\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from src.data_preparation import dataset\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "PRETAIN_MODEL = \"inception_v1\"\n",
    "num_classes = 120\n",
    "WIDTH = 224\n",
    "INPUT_WIDTH= 224\n",
    "CHANNEL = 3\n",
    "\n",
    "TRAIN_TF_RECORDS = \"/data/dog_breeds/stanford_ds/train/train.tfrecord\"\n",
    "TRAIN_BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f954e3df8910>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mINPUT_WIDTH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         num_epochs=1)\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m#     images = tf.cast(images * 255, tf.uint8)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zhenxingzhang/Documents/2017/dog-breeds-classification/src/data_preparation/dataset.py\u001b[0m in \u001b[0;36mload_batch\u001b[0;34m(tf_record_name, batch_size, width, height, is_training, num_epochs, capacity, min_after_dequeue)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;31m# Preprocess image for usage by Inception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     image = inception_preprocessing.preprocess_image(image_raw, height, width,\n\u001b[0;32m--> 255\u001b[0;31m                                                      \u001b[0mbbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m                                                      \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                                                      add_image_summaries=False)\n",
      "\u001b[0;32m/Users/zhenxingzhang/Envs/tf_py2/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.pyc\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    210\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[1;32m    211\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[0;32m--> 212\u001b[0;31m           value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    213\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m/Users/zhenxingzhang/Envs/tf_py2/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.pyc\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m       \u001b[0m_AssertCompatible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m       \u001b[0mnparray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp_dt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m       \u001b[0;31m# check to them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m       \u001b[0;31m# We need to pass in quantized values as tuples, so don't apply the shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default(), tf.Session() as sess:\n",
    "    # First create the dataset and load one batch\n",
    "    images_raw, images, labels = dataset.load_batch(\n",
    "        TRAIN_TF_RECORDS,\n",
    "        TRAIN_BATCH_SIZE,\n",
    "        INPUT_WIDTH,\n",
    "        INPUT_WIDTH,\n",
    "        is_training=True,\n",
    "        num_epochs=1)\n",
    "#     images = tf.cast(images * 255, tf.uint8)\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    \n",
    "    with slim.queues.QueueRunners(sess):\n",
    "        image_raw_batch, image_batch = sess.run([images_raw, images])\n",
    "        print(image_batch.max(), image_batch.min())\n",
    "\n",
    "#     print(image_batch[0])   \n",
    "    image_precessed_batch = (image_batch * 127 + 127).astype(np.uint8)\n",
    "#     print(image_precessed_batch[0])\n",
    "    print(image_precessed_batch.max(), image_precessed_batch.min())\n",
    "    plt.imshow(image_precessed_batch[0])\n",
    "    plt.show()\n",
    "\n",
    "    plt.imshow(image_raw_batch[0, :].astype(np.uint8))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "[4.787492], [[-5.32276825e-14  1.64103621e-13 -7.32893455e-13  6.89111854e-13\n",
      "   1.12389292e-13  1.44264768e-13 -1.78983822e-13 -7.18660049e-13\n",
      "   6.08263914e-14  6.99800081e-13 -1.90176922e-13 -4.03928261e-14\n",
      "  -2.66548556e-13  6.79433452e-14 -8.52541074e-13 -7.89342753e-14\n",
      "  -1.41762375e-13  4.97536636e-13 -1.53853140e-13  4.76851496e-14\n",
      "  -2.65714439e-14  1.76175020e-13 -1.09750926e-13 -5.15103436e-14\n",
      "   8.16989705e-13  1.61399621e-13  2.06371758e-13 -1.54762501e-13\n",
      "  -4.94505316e-13  5.41010379e-13  1.20434993e-13  1.96137730e-13\n",
      "   1.31995630e-12  5.86474025e-14  2.56242591e-13 -6.64955775e-13\n",
      "   4.17993846e-13  2.32445329e-13  1.87418278e-13  4.63848794e-16\n",
      "  -5.19684176e-13 -3.54817819e-13  1.72257906e-13  2.00170067e-13\n",
      "   9.92542298e-14 -1.42187423e-13 -7.00591278e-13  3.79204860e-14\n",
      "  -9.12988435e-13 -2.02091084e-13 -4.35360976e-13  6.49601832e-14\n",
      "   2.85671552e-13  4.60904101e-14  4.21625625e-13  4.59204940e-13\n",
      "  -2.72722003e-13  2.80958067e-14  4.06786584e-13 -8.00218344e-13\n",
      "   3.10915370e-14 -2.35106747e-13  3.26252941e-13  2.69216019e-13\n",
      "   6.10218365e-13 -2.80783453e-13  3.50386712e-13 -7.39216956e-13\n",
      "  -3.49628611e-13 -2.77620104e-13 -7.92904425e-14 -1.10811086e-13\n",
      "  -1.63318333e-13  3.66710189e-13 -4.81007161e-13 -3.12389546e-13\n",
      "  -3.52576258e-13 -2.52885522e-13 -1.88418996e-13  8.88635574e-13\n",
      "  -7.82698762e-14 -2.30488805e-13  3.05800876e-13  1.66355943e-13\n",
      "  -2.14030765e-13 -2.63369242e-13  8.21656328e-13  6.09790538e-14\n",
      "   2.98129441e-14 -2.45495220e-13 -1.02083869e-14 -1.04405281e-13\n",
      "   1.46193360e-13 -2.68287698e-13 -2.45513598e-13 -8.58939181e-15\n",
      "   5.88329678e-13 -1.67244352e-13  3.09525544e-13  1.24834821e-13\n",
      "   9.67330166e-13  1.30664793e-13  9.20049410e-13  7.84242571e-13\n",
      "  -4.30034643e-13  2.85690742e-13 -8.68110447e-14 -7.63219186e-13\n",
      "  -5.62034577e-13 -3.52323097e-13  2.34127930e-13  2.59461804e-13\n",
      "   3.28289614e-13  5.15178720e-14 -4.29102622e-14 -6.99141062e-14\n",
      "   4.15290306e-13 -4.64385583e-13  1.71433556e-14  6.19506074e-14]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default(), tf.Session() as sess:\n",
    "    x_input = tf.placeholder(tf.float32, [None, WIDTH, HEIGHT, CHANNEL])\n",
    "    label = tf.placeholder(tf.int64)\n",
    "    \n",
    "    net_fn = nets_factory.get_network_fn(\n",
    "            PRETAIN_MODEL,\n",
    "            num_classes,\n",
    "            is_training=False)\n",
    "    \n",
    "    logits, end_points = net_fn(x_input)\n",
    "    predictions = end_points['Predictions']\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=label, logits=logits)\n",
    "    \n",
    "    x = np.ones([1, HEIGHT, WIDTH, CHANNEL])\n",
    "    loss_, logits_ = sess.run([loss, logits], {x_input: x, label: [1]})\n",
    "    print(\"{}, {}\".format(loss_, logits_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
